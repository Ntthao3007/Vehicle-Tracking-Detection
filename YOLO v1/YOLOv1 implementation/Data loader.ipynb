{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Transforms the training images and labels into tensors and loads them into the train_data list as \n",
    "tuples.\n",
    "\"\"\"\n",
    "def DataLoader():\n",
    "    train_files, target_files = FilesLoader()\n",
    "    \n",
    "    for i in range(len(train_files)):\n",
    "        if i == 1:\n",
    "            break\n",
    "        \n",
    "        # Extracts a single random image and the corresponding label, and transforms them into\n",
    "        # tensors. Both are appended to the train_data list in form of a tuple.\n",
    "        extract_image_and_label(train_files, target_files) \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loads the images and the label file using the respective system path.\n",
    "Returns:\n",
    "    train_files (list): List containing all image names from the folder.\n",
    "    target_files (list): List containg the labels in the form of a json datastructure\n",
    "\"\"\"\n",
    "def FilesLoader():\n",
    "    # All image names from the directory are loaded into the list train_files.\n",
    "    global train_files\n",
    "    train_files = listdir(train_files_path)\n",
    "    # The json file containing the labels is loaded into the list target_files.\n",
    "    f = open(target_files_path)\n",
    "    target_files = json.load(f)\n",
    "    return train_files, target_files\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Chooses a random image which is then being transformed into a tensor and stored.\n",
    "Finds the corresponding label inside the json file which is then being transformed into a tensor\n",
    "and stored. Stores both tensors in a tuple inside the train_data list.\n",
    "Parameters:\n",
    "    train_files (list): A list containing the names of all images from the image folder\n",
    "    target_files (list): A list containing the json object with all the labels.\n",
    "\"\"\"\n",
    "def extract_image_and_label(train_files, target_files):\n",
    "    img_tensor, chosen_image = extract_image(train_files)\n",
    "    target_tensor = extract_json_label(target_files, chosen_image)\n",
    "    \n",
    "    train_data.append((img_tensor, target_tensor))\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Finds a random image from the folder and applies the transform to it. \n",
    "Parameters:\n",
    "    train_files (list): A list containing the names of all images from the image folder\n",
    "Returns:\n",
    "    img_tensor (tensor): The tensor which contains the image values\n",
    "    f (string): The string name of the image file\n",
    "\"\"\"    \n",
    "def extract_image(train_files):\n",
    "    f = random.choice(train_files)\n",
    "    train_files.remove(f)\n",
    "    global img\n",
    "    img = Image.open(train_files_path + f)\n",
    "    img_tensor = transform(img) # Apply the transform to the image.\n",
    "    return img_tensor, f\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Uses the name of the image to find the corresponding json element. Then it extracts the data and\n",
    "transforms it into a tensor which is stored inside the train_data list.\n",
    "Parameters:\n",
    "    target_files (list): A list containing the json object with all the labels.\n",
    "    chosen_image (string): The name of the image for which the label is needed.\n",
    "Returns:\n",
    "    target_tensor (tensor): The tensor which contains the image labels\n",
    "\"\"\"\n",
    "def extract_json_label(target_files, chosen_image):\n",
    "    for json in target_files:\n",
    "        if json['name'] == chosen_image:\n",
    "            img_label = json\n",
    "            break\n",
    "            \n",
    "    target_tensor = transform_label_to_tensor(img_label)\n",
    "\n",
    "    return target_tensor\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Extracts the useful information from the json object and transforms them into a tensor.\n",
    "Parameters:\n",
    "    img_label (): A specific json element\n",
    "Returns:\n",
    "    target_tensor (tensor): A tensor of size (5+num_classes,cells,cells) which is used as the target of \n",
    "    the image.\n",
    "\"\"\"\n",
    "def transform_label_to_tensor(img_label):\n",
    "    target_tensor = torch.zeros(5+num_classes, cells, cells) # Here are the information stored\n",
    "    \n",
    "    for labels in range(len(img_label[\"labels\"])):\n",
    "        \n",
    "        # Store the category index if its contained within the category_list.\n",
    "        category = img_label[\"labels\"][labels][\"category\"]         \n",
    "        if category not in category_list:\n",
    "            continue\n",
    "        ctg_idx = category_list.index(category)\n",
    "        \n",
    "        # Store the bounding box information and rescale it by the resize factor.\n",
    "        x1 = img_label[\"labels\"][labels][\"box2d\"][\"x1\"] * (448/img.size[0])\n",
    "        y1 = img_label[\"labels\"][labels][\"box2d\"][\"y1\"] * (448/img.size[1])\n",
    "        x2 = img_label[\"labels\"][labels][\"box2d\"][\"x2\"] * (448/img.size[0])\n",
    "        y2 = img_label[\"labels\"][labels][\"box2d\"][\"y2\"] * (448/img.size[1])\n",
    "        debug_labels.append([ctg_idx,x1,y1,x2,y2]) # ToDo: delete this\n",
    "\n",
    "        # Transforms the corner bounding box information into a mid bounding box information\n",
    "        x_mid = abs(x2 - x1) / 2 + x1\n",
    "        y_mid = abs(y2 - y1) / 2 + y1\n",
    "        width = abs(x2 - x1) \n",
    "        height = abs(y2 - y1) \n",
    "        \n",
    "        # Size of a single cell\n",
    "        cell_dim = int(448 / cells)\n",
    "        \n",
    "        # Determines the cell position of the bounding box\n",
    "        cell_pos_x = int(x_mid // cell_dim)\n",
    "        cell_pos_y = int(y_mid // cell_dim)\n",
    "        \n",
    "        # Stores the information inside the target_tensor\n",
    "        target_tensor[0][cell_pos_y][cell_pos_x] = 1\n",
    "        target_tensor[1][cell_pos_y][cell_pos_x] = (x_mid % cell_dim) / cell_dim\n",
    "        target_tensor[2][cell_pos_y][cell_pos_x] = (y_mid % cell_dim) / cell_dim\n",
    "        target_tensor[3][cell_pos_y][cell_pos_x] = width / 448\n",
    "        target_tensor[4][cell_pos_y][cell_pos_x] = height / 448\n",
    "        target_tensor[ctg_idx+5][cell_pos_y][cell_pos_x] = 1\n",
    "\n",
    "    return target_tensor\n",
    "\n",
    "# Define transform which is applied to every single image to resize and convert it into a tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448,448), Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# System paths to the train images and the label file\n",
    "# ToDo: Adapt this to only use the respective folder location\n",
    "train_files_path = 'C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k/images/100k/val/'\n",
    "target_files_path = 'C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k_labels_release/bdd100k/labels/det_v2_val_release.json'\n",
    "\n",
    "# Reference list to all the label categories for object detection\n",
    "category_list = [\"other vehicle\", \"pedestrian\", \"traffic light\", \"traffic sign\", \"truck\", \"train\", \"other person\", \"bus\", \"car\", \"rider\", \"motorcycle\", \"bicycle\", \"trailer\"]\n",
    "\n",
    "# Number of classes from the dataset\n",
    "num_classes = len(category_list)\n",
    "\n",
    "# Determines how many cells the YOLO grid contains\n",
    "cells = 14\n",
    "\n",
    "# Will contain all training image tensors and the corresponding label tensors in the form of tuples\n",
    "train_data = []\n",
    "debug_labels = [] # ToDo: delete this\n",
    "\n",
    "# Fills the train_data list with the tuples\n",
    "DataLoader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Used for printing the bounding box directly from the dataset\n",
    "color = (0, 255, 0)\n",
    "thickness = 1\n",
    "image = train_data[0][0].numpy().transpose(1, 2, 0)\n",
    "img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "       \n",
    "for i in range(len(debug_labels)):\n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2]))\n",
    "    end_point = (int(debug_labels[i][3]),int(debug_labels[i][4]))\n",
    "    cv2.rectangle(img_rgb, start_point, end_point, color, thickness)\n",
    "    \n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2])-10)\n",
    "    cv2.putText(img_rgb, str(category_list[debug_labels[i][0]]), start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow(\"image\", img_rgb)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Used to print the bounding box from the tensor structures\n",
    "image2 = train_data[0][0].numpy().transpose(1, 2, 0)\n",
    "img_rgb2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cell_dim = int(448 / cells)\n",
    "\n",
    "for h in range(cells):\n",
    "    for w in range(cells):\n",
    "        if train_data[0][1][0,h,w] == 0:\n",
    "            continue\n",
    "        centre_x = train_data[0][1][1,h,w]*cell_dim + cell_dim*w\n",
    "        centre_y = train_data[0][1][2,h,w]*cell_dim + cell_dim*h\n",
    "        width = train_data[0][1][3,h,w] * 448\n",
    "        height = train_data[0][1][4,h,w] * 448\n",
    "        \n",
    "        start_point = (int(centre_x - width/2), int(centre_y - height/2))\n",
    "        end_point = (int(centre_x + width/2), int(centre_y + height/2))\n",
    "        cv2.rectangle(img_rgb2, start_point, end_point, color, thickness)\n",
    "        \n",
    "        for i in range(13):\n",
    "            if train_data[0][1][i+5,h,w] == 1:\n",
    "                category_idx = i\n",
    "                break\n",
    "        start_point = (int(centre_x - width/2),int(centre_y - height/2)-10)\n",
    "        cv2.putText(img_rgb2, str(category_list[category_idx]), start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "cv2.imshow(\"image\", img_rgb2)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
