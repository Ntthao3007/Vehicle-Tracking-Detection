{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.301307574999996 241.45427133333334 116.60261514999999 159.9343405333333\n",
      "131.45088827499998 228.5632313630042 56.77280945 70.81213727399168\n",
      "153.5049411 214.66772165309845 40.6143941 56.67290161730804\n",
      "173.3754239 209.0599330578272 20.08884009999997 45.45732442676558\n",
      "182.546416675 210.01086835555557 9.607706149999984 24.067788266666696\n",
      "184.07491532499998 204.96439755555556 14.41155974999998 27.949690222222216\n",
      "193.68262095 205.74077782222224 8.297564099999988 17.08036648888887\n",
      "200.2333298 201.0824965333333 9.170992599999977 10.869323733333346\n",
      "205.47389694999998 197.2005948888889 7.4241362999999865 12.42208488888889\n",
      "211.151177825 196.81240382222222 2.1835691499999825 8.540182933333341\n",
      "344.785636125 218.93924235555556 118.34947145000001 136.64293128888892\n",
      "283.427330725 211.48555395283572 36.68396865 64.283412261227\n",
      "262.02834909999996 210.39905911111111 19.215412299999997 43.47729742222225\n",
      "251.11050107499997 207.29353742222224 19.21541265000002 29.502450133333383\n",
      "241.284437975 204.18801666666667 10.917847850000015 23.291408622222264\n",
      "235.38880014999998 204.96439724444446 6.113994599999955 15.527605333333327\n",
      "231.67673217499998 203.02344626666667 6.550708850000007 11.64570337777775\n",
      "227.74630672499998 199.52973475555555 6.550708849999978 9.316563200000019\n",
      "224.03423822499997 198.3651649777778 4.367139349999974 8.540182933333341\n",
      "tensor(176.5277) tensor(212.8610) tensor(45.4573) tensor(20.0888)\n",
      "tensor(214.9903) tensor(200.3908) tensor(8.5402) tensor(2.1836)\n",
      "tensor(228.1076) tensor(201.9718) tensor(8.5402) tensor(4.3671)\n",
      "tensor(288.5805) tensor(215.3307) tensor(64.2834) tensor(36.6840)\n",
      "tensor(351.0545) tensor(222.9200) tensor(136.6429) tensor(118.3495)\n",
      "tensor(59.3613) tensor(245.8443) tensor(159.9343) tensor(116.6026)\n",
      "tensor(133.8409) tensor(232.7189) tensor(70.8121) tensor(56.7728)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Transforms the training images and labels into tensors and loads them into the train_data list as \n",
    "tuples.\n",
    "\"\"\"\n",
    "def DataLoader():\n",
    "    train_files, target_files = FilesLoader()\n",
    "    \n",
    "    for i in range(len(train_files)):\n",
    "        if i == 1:\n",
    "            break\n",
    "        \n",
    "        # Extracts a single random image and the corresponding label, and transforms them into\n",
    "        # tensors. Both are appended to the train_data list in form of a tuple.\n",
    "        extract_image_and_label(train_files, target_files) \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loads the images and the label file using the respective system path.\n",
    "Returns:\n",
    "    train_files (list): List containing all image names from the folder.\n",
    "    target_files (list): List containg the labels in the form of a json datastructure\n",
    "\"\"\"\n",
    "def FilesLoader():\n",
    "    # All image names from the directory are loaded into the list train_files.\n",
    "    global train_files\n",
    "    train_files = listdir(train_files_path)\n",
    "    # The json file containing the labels is loaded into the list target_files.\n",
    "    f = open(target_files_path)\n",
    "    target_files = json.load(f)\n",
    "    return train_files, target_files\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Chooses a random image which is then being transformed into a tensor and stored.\n",
    "Finds the corresponding label inside the json file which is then being transformed into a tensor\n",
    "and stored. Stores both tensors in a tuple inside the train_data list.\n",
    "Parameters:\n",
    "    train_files (list): A list containing the names of all images from the image folder\n",
    "    target_files (list): A list containing the json object with all the labels.\n",
    "\"\"\"\n",
    "def extract_image_and_label(train_files, target_files):\n",
    "    img_tensor, chosen_image = extract_image(train_files)\n",
    "    target_tensor = extract_json_label(target_files, chosen_image)\n",
    "    \n",
    "    train_data.append((img_tensor, target_tensor))\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Finds a random image from the folder and applies the transform to it. \n",
    "Parameters:\n",
    "    train_files (list): A list containing the names of all images from the image folder\n",
    "Returns:\n",
    "    img_tensor (tensor): The tensor which contains the image values\n",
    "    f (string): The string name of the image file\n",
    "\"\"\"    \n",
    "def extract_image(train_files):\n",
    "    f = random.choice(train_files)\n",
    "    train_files.remove(f)\n",
    "    global img\n",
    "    img = Image.open(train_files_path + f)\n",
    "    img_tensor = transform(img) # Apply the transform to the image.\n",
    "    return img_tensor, f\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Uses the name of the image to find the corresponding json element. Then it extracts the data and\n",
    "transforms it into a tensor which is stored inside the train_data list.\n",
    "Parameters:\n",
    "    target_files (list): A list containing the json object with all the labels.\n",
    "    chosen_image (string): The name of the image for which the label is needed.\n",
    "Returns:\n",
    "    target_tensor (tensor): The tensor which contains the image labels\n",
    "\"\"\"\n",
    "def extract_json_label(target_files, chosen_image):\n",
    "    for json in target_files:\n",
    "        if json['name'] == chosen_image:\n",
    "            img_label = json\n",
    "            break\n",
    "            \n",
    "    target_tensor = transform_label_to_tensor(img_label)\n",
    "\n",
    "    return target_tensor\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Extracts the useful information from the json object and transforms them into a tensor.\n",
    "Parameters:\n",
    "    img_label (): A specific json element\n",
    "Returns:\n",
    "    target_tensor (tensor): A tensor of size (18,cells,cells) which is used as the target of \n",
    "    the image.\n",
    "\"\"\"\n",
    "def transform_label_to_tensor(img_label):\n",
    "    target_tensor = torch.zeros(18, cells, cells) # Here are the information stored\n",
    "    \n",
    "    for labels in range(len(img_label[\"labels\"])):\n",
    "        \n",
    "        # Store the category index if its contained within the category_list.\n",
    "        category = img_label[\"labels\"][labels][\"category\"]         \n",
    "        if category not in category_list:\n",
    "            continue\n",
    "        ctg_idx = category_list.index(category)\n",
    "        \n",
    "        # Store the bounding box information and rescale it by the resize factor.\n",
    "        x1 = img_label[\"labels\"][labels][\"box2d\"][\"x1\"] * (448/img.size[0])\n",
    "        y1 = img_label[\"labels\"][labels][\"box2d\"][\"y1\"] * (448/img.size[1])\n",
    "        x2 = img_label[\"labels\"][labels][\"box2d\"][\"x2\"] * (448/img.size[0])\n",
    "        y2 = img_label[\"labels\"][labels][\"box2d\"][\"y2\"] * (448/img.size[1])\n",
    "        \n",
    "        # Transforms the corner bounding box information into a mid bounding box information\n",
    "        x_mid = abs(x2 - x1) / 2 + x1\n",
    "        y_mid = abs(y2 - y1) / 2 + y1\n",
    "        width = abs(x2 - x1) \n",
    "        height = abs(y2 - y1) \n",
    "        print(x_mid, y_mid, width, height)\n",
    "        \n",
    "        # Size of a single cell\n",
    "        cell_dim = int(448 / cells)\n",
    "        \n",
    "        # Determines the cell position of the bounding box\n",
    "        cell_pos_x = int(x_mid // cell_dim)\n",
    "        cell_pos_y = int(y_mid // cell_dim)\n",
    "        \n",
    "        # Stores the information inside the target_tensor\n",
    "        target_tensor[0][cell_pos_y][cell_pos_x] = 1\n",
    "        target_tensor[1][cell_pos_y][cell_pos_x] = (x_mid % cell_dim) / cell_dim\n",
    "        target_tensor[2][cell_pos_y][cell_pos_x] = (y_mid % cell_dim) / cell_dim\n",
    "        target_tensor[3][cell_pos_y][cell_pos_x] = width / 448\n",
    "        target_tensor[4][cell_pos_y][cell_pos_x] = height  / 448\n",
    "\n",
    "    #print (target_tensor)\n",
    "    return target_tensor\n",
    "\n",
    "\n",
    "# Define transform which is applied to every single image to resize and convert it into a tensor.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448,448), Image.NEAREST),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# System paths to the train images and the label file.\n",
    "# ToDo: Adapt this to only use the respective folder location.\n",
    "train_files_path = 'C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k/images/100k/val/'\n",
    "target_files_path = 'C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k_labels_release/bdd100k/labels/det_v2_val_release.json'\n",
    "\n",
    "# Reference list to all the label categories for object detection.\n",
    "category_list = [\"other vehicle\", \"pedestrian\", \"traffic light\", \"traffic sign\", \"truck\", \"train\", \"other person\", \"bus\", \"car\", \"rider\", \"motorcycle\", \"bicycle\", \"trailer\"]\n",
    "\n",
    "# Determines how many cells the YOLO grid contains\n",
    "cells = 10\n",
    "\n",
    "# Will contain all training image tensors and the corresponding label tensors in the form of tuples.\n",
    "train_data = []\n",
    "\n",
    "# Fills the train_data with the tuples.\n",
    "DataLoader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "image = train_data[0][0].numpy().transpose(1, 2, 0)\n",
    "img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#cv2.imshow(\"image\", img_rgb)\n",
    "#cv2.waitKey()\n",
    "\n",
    "labels = train_data[0][1]\n",
    "#print(labels)\n",
    "color = (0, 255, 0)\n",
    "thickness = 1\n",
    "\n",
    "cell_dim = 448 / cells\n",
    "for cell_y in range(cells):\n",
    "    for cell_x in range(cells):\n",
    "        if labels[0,cell_y,cell_x] != 0:\n",
    "            centre_pix_x = cell_x * cell_dim + cell_dim*labels[1, cell_y, cell_x]\n",
    "            centre_pix_y = cell_y * cell_dim + cell_dim*labels[2, cell_y, cell_x]\n",
    "            h_pix = labels[3, cell_y, cell_x] * 448\n",
    "            w_pix = labels[4, cell_y, cell_x] * 448\n",
    "            print(centre_pix_x, centre_pix_y, w_pix, h_pix)\n",
    "            \n",
    "            \n",
    "            start_point = (int(centre_pix_x - w_pix/2),int(centre_pix_y - h_pix/2))\n",
    "            end_point = (int(centre_pix_x + w_pix/2),int(centre_pix_y + h_pix/2))\n",
    "\n",
    "            cv2.rectangle(img_rgb, start_point, end_point, color, thickness)\n",
    "            \n",
    "\n",
    "cv2.imshow(\"image\", img_rgb)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "image = train_data[0][0].numpy().transpose(1, 2, 0)\n",
    "img_rgb2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\"\"\"        \n",
    "for i in range(len(debug_labels)):\n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2]))\n",
    "    end_point = (int(debug_labels[i][3]),int(debug_labels[i][4]))\n",
    "\n",
    "    cv2.rectangle(img_rgb, start_point, end_point, color, thickness)\n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2])-10)\n",
    "    cv2.putText(img_rgb, str(category_list[debug_labels[i][0]]), start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\"\"\"      \n",
    "print(len(train_data_list))\n",
    "print(len(train_labels_list))\n",
    "# This code produces the bounding boxes for debugging.\n",
    "%matplotlib inline        \n",
    "color = (0, 255, 0)\n",
    "thickness = 2\n",
    "image = cv2.imread(debug_images[0])\n",
    "image = cv2.resize(image, (448, 448),interpolation = cv2.INTER_AREA)\n",
    "for i in range(len(debug_labels)):\n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2]))\n",
    "    end_point = (int(debug_labels[i][3]),int(debug_labels[i][4]))\n",
    "\n",
    "    cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "    start_point = (int(debug_labels[i][1]),int(debug_labels[i][2])-10)\n",
    "    cv2.putText(image, str(category_list[debug_labels[i][0]]), start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('a', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
