{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def TrainNetwork(num_epochs):\n",
    "    \"\"\"\n",
    "    Starts the training process of the model.\n",
    "    Parameters:\n",
    "        num_epochs (int): Amount of epochs for training the model\n",
    "    \"\"\"\n",
    "    \n",
    "    data = DataLoader(train_files_path, target_files_path, category_list, split_size, batch_size, train_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # if there are still unsused images in the image folder, load a new set of batches\n",
    "        if len(data.train_files) > 0:\n",
    "            print(\"LOADING NEW BATCHES\")\n",
    "            print(\"\")\n",
    "            data.LoadData()\n",
    "        else: # if all images have been used, load a new instance and repeat the process\n",
    "            print(\"DATA IS BEING LOADED FOR A NEW EPOCH\")\n",
    "            print(\"\")\n",
    "            data = DataLoader(train_files_path, target_files_path, category_list, split_size, batch_size, train_size)\n",
    "            data.LoadFiles()\n",
    "            data.LoadData()\n",
    "        \n",
    "        for batch_idx, (train_data, target_data) in enumerate(data.train_data):\n",
    "            train_data = train_data.to(device)\n",
    "            target_data = target_data.to(device)\n",
    "            \n",
    "            predictions = model(train_data)\n",
    "            loss = YOLO_Loss(predictions, target_data, split_size, num_boxes, num_classes, lambda_coord, lambda_noobj)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            print('Train Epoch: {} of {} [Batch: {}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, num_epochs, batch_idx, len(data.train_data),\n",
    "                batch_idx / len(train_data) * 100., loss.data.item()))\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "train_files_path = \"C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k/images/100k/val/\"\n",
    "target_files_path = \"C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k_labels_release/bdd100k/labels/det_v2_val_release.json\"\n",
    "category_list = [\"other vehicle\", \"pedestrian\", \"traffic light\", \"traffic sign\", \"truck\", \"train\", \"other person\", \"bus\", \"car\", \"rider\", \"motorcycle\", \"bicycle\", \"trailer\"]\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "split_size = 7\n",
    "num_boxes = 2\n",
    "num_classes = len(category_list)\n",
    "lambda_coord = 5\n",
    "lambda_noobj = 5\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "train_size = 5000\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "model = YOLOv1(split_size, num_boxes, num_classes).to(device)\n",
    "\n",
    "# Define the learning method as stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Start the training process\n",
    "TrainNetwork(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
