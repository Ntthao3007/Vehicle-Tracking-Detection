{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    \"\"\"\n",
    "    This class uses its attributes to load the training data and transforms it into tensors.\n",
    "    The tensors are then stored in mini-batches inside the train_data list which is the final \n",
    "    product of this class. Multiple function calls of LoadData() will initialize the train_data \n",
    "    list with new tensors from the training data, excluding all the previous ones. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_files_path, target_files_path, category_list, split_size, batch_size, train_size):\n",
    "        \"\"\"\n",
    "        Initialize all parameters for loading and transforming the data into tensors.\n",
    "        \n",
    "        Parameters:\n",
    "            train_files_path (string): The path to the train image folder\n",
    "            target_files_path (string): The path to the json file containg the image labels\n",
    "            category_list (list): Reference list to all the label categories for object detection\n",
    "            split_size (int): Amount of grid cells\n",
    "            batch_size (int): Batch size\n",
    "            train_size (int): Amount of images which are loaded as training data for one epoch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_files_path = train_files_path\n",
    "        self.target_files_path = target_files_path       \n",
    "        self.category_list = category_list        \n",
    "        self.num_classes = len(category_list)       \n",
    "        self.cells = split_size        \n",
    "        self.batch_size = batch_size      \n",
    "        self.train_size = train_size\n",
    "        \n",
    "        self.train_files = [] # Will contain the remaining image names from the folder\n",
    "        self.target_files = [] # Will contain the json elements with the ground-truth labels\n",
    "        \n",
    "        self.train_data = [] # Will contain tuples with mini-batches of image and label tensors    \n",
    "        self.img_tensors = [] # Used to temporary store samples from a single batch\n",
    "        self.target_tensors = [] # Used to temporary store samples from a single batch\n",
    "        \n",
    "        # Define transform which is applied to every single image to resize and convert it into a tensor\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((448,448), Image.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "    \n",
    "\n",
    "    def LoadFiles(self):\n",
    "        \"\"\"\n",
    "        First function to be executed.\n",
    "        Loads the images and the label file using the respective system path.\n",
    "        \"\"\"\n",
    "            \n",
    "        # All image names from the directory are loaded into the list train_files.\n",
    "        self.train_files = listdir(self.train_files_path)\n",
    "        \n",
    "        # The json file containing the labels is loaded into the list target_files.\n",
    "        f = open(self.target_files_path)\n",
    "        self.target_files = json.load(f)\n",
    "        \n",
    "        \n",
    "    def LoadData(self):\n",
    "        \"\"\"\n",
    "        Transforms the training images and labels into tensors and loads them into batches. Once a batch is\n",
    "        full, it is stored in the train_data list. Fills the train_data list with batches until the desired\n",
    "        train_size is reached. Every image that is loaded, is being excluded from future calls of this \n",
    "        function.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Reset the cache\n",
    "        self.train_data = []    \n",
    "        self.img_tensors = [] \n",
    "        self.target_tensors = [] \n",
    "\n",
    "        for i in range(len(self.train_files)):\n",
    "            if i == self.train_size:\n",
    "                break # The train_data list is full with the desired amount of batches\n",
    "                \n",
    "            # Check if batch is full and perhaps start a new one\n",
    "            if len(self.img_tensors) >= self.batch_size:\n",
    "                self.train_data.append((torch.stack(self.img_tensors), self.target_tensors))\n",
    "                self.img_tensors = []\n",
    "                self.target_tensors = []\n",
    "                print('Loaded batch ', len(self.train_data), 'of ', int(self.train_size/self.batch_size))\n",
    "                print('Percentage Done: ', round(len(self.train_data)/int(self.train_size/self.batch_size)*100., 2), '%')\n",
    "                print('')\n",
    "                \n",
    "            # Extracts a single random image and the corresponding label, and transforms them into\n",
    "            # tensors. Both are appended to the img_tensors and target_tensors lists\n",
    "            self.extract_image_and_label() \n",
    "\n",
    "\n",
    "    def extract_image_and_label(self):\n",
    "        \"\"\"\n",
    "        Chooses a random image which is then being transformed into a tensor and stored.\n",
    "        Finds the corresponding label inside the json file which is then being transformed into a tensor\n",
    "        and stored. Stores both tensors inside the img_tensors and target_tensors lists.\n",
    "        \"\"\"\n",
    "        \n",
    "        img_tensor, chosen_image = self.extract_image()\n",
    "        target_tensor = self.extract_json_label(chosen_image)\n",
    "\n",
    "        self.img_tensors.append(img_tensor)\n",
    "        self.target_tensors.append(target_tensor)\n",
    "\n",
    "        \n",
    "    def extract_image(self):   \n",
    "        \"\"\"\n",
    "        Finds a random image from the train_files list and applies the transform to it. \n",
    " \n",
    "        Returns:\n",
    "            img_tensor (tensor): The tensor which contains the image values\n",
    "            f (string): The string name of the image file\n",
    "        \"\"\"    \n",
    "        \n",
    "        f = random.choice(self.train_files)\n",
    "        self.train_files.remove(f)\n",
    "        global img\n",
    "        img = Image.open(self.train_files_path + f)\n",
    "        img_tensor = self.transform(img) # Apply the transform to the image.\n",
    "        return img_tensor, f\n",
    "\n",
    "\n",
    "    def extract_json_label(self, chosen_image):\n",
    "        \"\"\"\n",
    "        Uses the name of the image to find the corresponding json element. Then it extracts the data and\n",
    "        transforms it into a tensor which is stored inside the target_tensors list.\n",
    "\n",
    "        Parameters:\n",
    "            chosen_image (string): The name of the image for which the label is needed.\n",
    "\n",
    "        Returns:\n",
    "            target_tensor (tensor): The tensor which contains the image labels\n",
    "        \"\"\"\n",
    "        \n",
    "        for json in self.target_files:\n",
    "            if json['name'] == chosen_image:\n",
    "                img_label = json\n",
    "                break\n",
    "\n",
    "        target_tensor = self.transform_label_to_tensor(img_label)\n",
    "        return target_tensor\n",
    "\n",
    "\n",
    "    def transform_label_to_tensor(self, img_label):\n",
    "        \"\"\"\n",
    "        Extracts the useful information from the json element and transforms them into a tensor.\n",
    "        \n",
    "        Parameters:\n",
    "            img_label (): A specific json element\n",
    "            \n",
    "        Returns:\n",
    "            target_tensor (tensor): A tensor of size (5+num_classes,cells,cells) which is used as the target of \n",
    "            the image.\n",
    "        \"\"\"\n",
    "        \n",
    "        target_tensor = torch.zeros(5+self.num_classes, self.cells, self.cells) # Here are the information stored\n",
    "\n",
    "        for labels in range(len(img_label[\"labels\"])):\n",
    "\n",
    "            # Store the category index if its contained within the category_list.\n",
    "            category = img_label[\"labels\"][labels][\"category\"]         \n",
    "            if category not in self.category_list:\n",
    "                continue\n",
    "            ctg_idx = self.category_list.index(category)\n",
    "\n",
    "            # Store the bounding box information and rescale it by the resize factor.\n",
    "            x1 = img_label[\"labels\"][labels][\"box2d\"][\"x1\"] * (448/img.size[0])\n",
    "            y1 = img_label[\"labels\"][labels][\"box2d\"][\"y1\"] * (448/img.size[1])\n",
    "            x2 = img_label[\"labels\"][labels][\"box2d\"][\"x2\"] * (448/img.size[0])\n",
    "            y2 = img_label[\"labels\"][labels][\"box2d\"][\"y2\"] * (448/img.size[1])\n",
    "\n",
    "            # Transforms the corner bounding box information into a mid bounding box information\n",
    "            x_mid = abs(x2 - x1) / 2 + x1\n",
    "            y_mid = abs(y2 - y1) / 2 + y1\n",
    "            width = abs(x2 - x1) \n",
    "            height = abs(y2 - y1) \n",
    "\n",
    "            # Size of a single cell\n",
    "            cell_dim = int(448 / self.cells)\n",
    "\n",
    "            # Determines the cell position of the bounding box\n",
    "            cell_pos_x = int(x_mid // cell_dim)\n",
    "            cell_pos_y = int(y_mid // cell_dim)\n",
    "\n",
    "            # Stores the information inside the target_tensor\n",
    "            if target_tensor[0][cell_pos_y][cell_pos_x] == 1: # Check if the cell already contains an object\n",
    "                continue\n",
    "            target_tensor[0][cell_pos_y][cell_pos_x] = 1\n",
    "            target_tensor[1][cell_pos_y][cell_pos_x] = (x_mid % cell_dim) / cell_dim\n",
    "            target_tensor[2][cell_pos_y][cell_pos_x] = (y_mid % cell_dim) / cell_dim\n",
    "            target_tensor[3][cell_pos_y][cell_pos_x] = width / 448\n",
    "            target_tensor[4][cell_pos_y][cell_pos_x] = height / 448\n",
    "            target_tensor[ctg_idx+5][cell_pos_y][cell_pos_x] = 1\n",
    "\n",
    "        return target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch  1 of  7\n",
      "Percentage Done:  14.29 %\n",
      "\n",
      "Loaded batch  2 of  7\n",
      "Percentage Done:  28.57 %\n",
      "\n",
      "Loaded batch  3 of  7\n",
      "Percentage Done:  42.86 %\n",
      "\n",
      "Loaded batch  4 of  7\n",
      "Percentage Done:  57.14 %\n",
      "\n",
      "Loaded batch  5 of  7\n",
      "Percentage Done:  71.43 %\n",
      "\n",
      "Loaded batch  6 of  7\n",
      "Percentage Done:  85.71 %\n",
      "\n",
      "Loaded batch  7 of  7\n",
      "Percentage Done:  100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Used for testing\n",
    "train_files_path = \"C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k/images/100k/val/\"\n",
    "target_files_path = \"C:/Users/alens/Desktop/Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning/YOLO v1/bdd100k_labels_release/bdd100k/labels/det_v2_val_release.json\"\n",
    "category_list = [\"other vehicle\", \"pedestrian\", \"traffic light\", \"traffic sign\", \"truck\", \"train\", \"other person\", \"bus\", \"car\", \"rider\", \"motorcycle\", \"bicycle\", \"trailer\"]\n",
    "split_size = 14\n",
    "batch_size = 64\n",
    "train_size = 500\n",
    "\n",
    "data = DataLoader(train_files_path, target_files_path, category_list, split_size, batch_size, train_size)\n",
    "data.LoadFiles()\n",
    "data.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for testing\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "color = (0, 255, 0)\n",
    "thickness = 1\n",
    "cell_dim = int(448/split_size)\n",
    "batch_idx = 0\n",
    "sample_idx = 1\n",
    "\n",
    "image = data.train_data[batch_idx][0][sample_idx].numpy().transpose(1, 2, 0)\n",
    "img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for h in range(split_size):\n",
    "    for w in range(split_size):\n",
    "        pass\n",
    "        if data.train_data[batch_idx][1][sample_idx][0,h,w] == 0:\n",
    "            continue\n",
    "        centre_x = data.train_data[batch_idx][1][sample_idx][1,h,w]*cell_dim + cell_dim*w\n",
    "        centre_y = data.train_data[batch_idx][1][sample_idx][2,h,w]*cell_dim + cell_dim*h\n",
    "        width = data.train_data[batch_idx][1][sample_idx][3,h,w] * 448\n",
    "        height = data.train_data[batch_idx][1][sample_idx][4,h,w] * 448\n",
    "        \n",
    "        start_point = (int(centre_x - width/2), int(centre_y - height/2))\n",
    "        end_point = (int(centre_x + width/2), int(centre_y + height/2))\n",
    "        cv2.rectangle(img_rgb, start_point, end_point, color, thickness)\n",
    "        \n",
    "        for i in range(13):\n",
    "            if data.train_data[batch_idx][1][sample_idx][i+5,h,w] == 1:\n",
    "                category_idx = i\n",
    "                break\n",
    "        start_point = (int(centre_x - width/2),int(centre_y - height/2)-10)\n",
    "        cv2.putText(img_rgb, str(category_list[category_idx]), start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow(\"image\", img_rgb)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for testing\n",
    "data.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c87b5546bee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;32min\u001b[0m  \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ma\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unknown error"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for (train_data, target_data)  in  data.train_data:\n",
    "    a = train_data\n",
    "    print(train_data.shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(data.train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataloader.ipynb\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-48a4a8609a42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;31m# run the code in themodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Real-time-Object-Detection-for-Autonomous-Driving-using-Deep-Learning\\YOLO v1\\YOLOv1 implementation\\dataloader.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msqueezenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\alexnet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
